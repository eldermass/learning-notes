# 爬虫实践

[入门博客](https://cuijiahua.com/blog/spider/)

[w3c](https://www.w3cschool.cn/python3/)

## 基本描述

[requests 中文 Doc](https://cn.python-requests.org/zh_CN/latest/)

[Beautiful Soup 中文 Doc](https://beautifulsoup.readthedocs.io/zh_CN/latest/)

[教程博文](https://blog.csdn.net/c406495762/article/details/78123502)

### 常用库

```python
# requests库 或 urllib库 请求、抓取网页数据
pip install requests

# 使用 Beautiful Soup 解析 html 文本
pip install beautifulsoup4

# scrapy 爬虫框架
# pyquery 库 解析html文本
# lxml.html.etree 解析html文本
# selenium 配合浏览器驱动 自动化操作
# pyecharts echarts 图形库
# jieba 中文断字解析
# scipy 科学计算、统计分析 库
# PIL 图形处理


```

## 常见问题

### 编码问题

```python
req = requests.get(url=url)
req.encoding            # 当前编码
req.apparent_encoding   # 页面的真实编码
req.encoding = 'GB2312' # 设为页面的真实编码，apparent_encoding
```

### base64 基本原理

<!-- https://blog.csdn.net/wo541075754/article/details/81734770 -->
```python
# 1. 三个字节一队，3 * 8 = 24 bit
# 2. 每6个bit一组，分为4组。24 / 6 = 4组，  每组2**6=64种可能就是所谓的base64
# 3. 每组前补两个0，组成一个字节，
# 4. 根据base64编码，把相应二进制转为字符， 不足用==补足
# 5. 结果资源变大1/3，约为原来的4/3

例如：
文本            a
asiic           97
二进制          011000  01(补0)     .       .
base64索引      24      16          .       .
base64          Y       Q           =       =

import base64
base64.b64encode('a'.encode()) # 结果为 YQ==

```

### session

```python
# 使用 requests 提供的会话管理
s = requests.session()
s.get()

```

### 文件存储

[pillow 常用方法](https://www.cnblogs.com/chimeiwangliang/p/7130434.html)

```python
req = requests.get(url=img_src, headers=headers, verify=False)
# 二进制
f = open('./a.jpg', 'ab') # 追加写入二进制， 不仅仅是图片
f.write(req.content)
f.close()

# urllib 库中下载文件的方法
from urllib.request import urlretrieve
urlretrieve(IMAGE_URL, './image/img1.png')

# 图片的其他方式
from PIL import Image
from io import BytesIO
i = Image.open(BytesIO(r.content))

```

### https 不友好

```python
# requests 库对 https 不友好，就用原生的解决， 或者使用 selenuim
url = 'https://qqchub.com/index.php/ajax/data.html?mid=1&page=1&limit=8&tid=all&by=t&level=1'

headers = {
    'Content-Type': 'application/json',
    "User-Agent": "Mozilla/5.0 (Linux; Android 8.0.0; MIX 2S Build/OPR1.170623.032)\
    AppleWebKit/537.36 (KHTML, like Gecko) Chrome/62.0.3202.84 Mobile Safari/537.36",
}

req = urllib.request.Request(url=url, headers=headers)

res = urllib.request.urlopen(req)

data = res.read().decode('utf-8')

data = json.loads(data)

f = open('list.txt', 'wb')

pickle.dump(data, f)
f.close()
```
