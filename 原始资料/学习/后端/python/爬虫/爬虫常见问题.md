# 常见问题

## 编码问题

```python
# response.content 是 bytes 类型，response.text 是用 response.content.decode(xx) 推断解码,一般是错的
response = requests.get(url)
response.encoding            # 当前推断的编码
response.apparent_encoding   # 页面的真实编码
response.encoding = 'GB2312' # 设为页面的真实编码，utf8，gbk
```

## 代理

```python
# 为了防止自己ip被封，一般会使用三方的高匿代理，百度可搜
# 通过修改下参数确定代理匿名程度，一般后两个隐藏
REMOTE_ADDR = Proxy_IP
HTTP_VIA = not determined
HTTP_X_FORWARDED_FOR = your IP
```

## CA 证书

```python
# 忽略 https 验证
request.get(url, verify=False)
```

## session 连续请求

```python
# 这样的请求会保持cookie状态
session = request.session()
response = session.get(url)
```

## xpath 语法

```python
# lxml 模块使用xpath语法解析 xml/html 数据
html = lxml.entre.HTML(html)
html.xpath('//a[@href="1.html"]/text()')
html.xpath('//a[contains(@href, ".html")]/text()')
```

## selenium

```python
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
driver = webdriver.Chrome(service=Service(executable_path='./path'))
driver.get('https://www.baidu.com')
driver.quit()

# 窗口句柄
driver.window_handles
# 切换窗口
driver.switch_to.window(driver.window_handles[-1])
# 执行js代码
driver.execute_script('js_script')

# 等待
time.sleep() # 强制等待
driver.implicitly_wait(20) # 隐式等待：找不到元素会继续找，直到超时才报错

# 无界面模式
from selenium.webdriver.chrome.options import Options
opt = Options()
opt.add_argument('--headless')
opt.add_argument('--disable-gpu')
webdriver.Chrome(options=opt)
```

## tesseract 图像识别引擎

```python
1. 安装引擎
2. pip install pillow
3. pip install pytesseract
# 腾讯，阿里，有道云ocr平台
```

## 使用类似 js2py 类似的模块尝试, pyv8 executejs splash

## scrapy 框架

```bash
scrapy startproject project_name
scrapy genspider spider_name domain
scrapy crawl spider_name --nolog
# crawlspider 模板
scrapy genspider -t crawl spider_name domain
# scrapy shell url调试代码
```
